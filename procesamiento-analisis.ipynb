{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Procesamiento Semántico de Palabras\n",
    "\n",
    "## 1.1 Propósito\n",
    "\n",
    "Se procesan una serie de textos y se obtiene el top k palabras más importantes y se exporta una lista para construir una nube de palabras a través de un programa externo.\n",
    "\n",
    "## 1.2 Metodología\n",
    "\n",
    "#### 1.2.1 Limpieza:\n",
    "- Convierte caracteres de utf8 a ascii y elimina errores.\n",
    "- Convierte mayúsculas en miinúsculas y quita acentos.\n",
    "- Elimina filas con entradas vacías.\n",
    "- Se deshace de palabras con un número de carácteres menor a 3.\n",
    "- Elimina stop [words](https://nlp.stanford.edu/IR-book/html/htmledition/dropping-common-terms-stop-words-1.html)\n",
    "\n",
    "#### 1.2.2 Vectorización TF-IDF\n",
    "\n",
    "- Genera un vectorizador de textos usando tf-idf.\n",
    "- Obtiene los vectores de importancia de palabra cada texto.\n",
    "\n",
    "\n",
    "Tf-idf significa *Term Frequency - Inverse Term Frequency*, tf-idf es utilizado en la recuperación de información y minería de texto. TF-idf es una medida estadística utilizada para evaluar la importancia de una palabra para un documento en una colección\n",
    "de textos o corpus.[2]\n",
    "\n",
    "En un corpus de texto grande, algunas palabras están muy presentes\n",
    "(por ejemplo, \"el\", \"a\", \"y\"), por lo tanto, llevarán muy poca información sobre el contenido real del\n",
    "documento. Si tuviéramos que alimentar los datos de conteo directamente a un\n",
    "clasificador, esos términos muy frecuentes tendrían mucho peso comparado\n",
    "con el peso de términos más raros pero más interesantes.[3]\n",
    "\n",
    "Usando la configuración predeterminada de [TfidfTransformer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html?highlight=tf%20idf#sklearn.feature_extraction.text.TfidfTransformer) de la libreriía Sci-Kit:\n",
    "\n",
    "    TfidfTransformer(norm = 'l2', use_idf = True,\n",
    "                     smooth_idf = True, sublinear_tf = False)\n",
    "\n",
    "La frecuencia del término es decir, el número de veces que se produce un\n",
    "término en un documento determinado, se multiplica con el componente idf, que\n",
    "es calculado como:\n",
    "\n",
    "\n",
    ">![Pipeline_inicial_sin_detalle](./assets/eq.png)\n",
    "\n",
    "#### Ejemplo\n",
    "\n",
    "    Considere un documento que contiene 100 palabras en el que la palabra gato\n",
    "    aparece 3 veces. El término frecuencia (es decir, tf) para gato es\n",
    "    (3/100) = 0.03. Ahora, supongamos que tenemos 10 millones de documentos y\n",
    "    la palabra gato aparece en mil de estos. La frecuencia inversa del\n",
    "    documento (es decir, idf) se calcula como log(10,000,001 / 1,000+1) = 4.\n",
    "    Por lo tanto, el peso Tf-idf es el producto de estas cantidades:\n",
    "    0.03 * 4 = 0.12.\n",
    "\n",
    "\n",
    "A continuación se muestra la matríz TF-IDF de un conjunto de documentos de\n",
    "diferentes temas tales como \"air\", \"pollution\", etc. con un conjunto de palabras\n",
    "etiquetadas como d0, d1, dn:\n",
    "\n",
    ">![Pipeline_inicial_sin_detalle](./assets/word_document.png)\n",
    "   Matríz de words-documents, cada columna corresponde a un documento, cada fila a una palabra. Una celda almacena la frecuencia de una palabra en un documento, las celdas oscuras indican altas frecuencias de palabras. La clusterización por topic Modelling agrupan los\n",
    "   documentos, que usan palabras similares, así como las palabras que aparecen\n",
    "   en un conjunto similar de documentos. Los patrones resultantes se\n",
    "   denominan \"temas\" o \"tópicos\".\n",
    "\n",
    "  Obtenido de: [http://www.issac-conference.org/2015/Slides/Moitra.pdf](http://www.issac-conference.org/2015/Slides/Moitra.pdf)\n",
    "  \n",
    "Finalmente se  extraen las  top-25 palabras para generar la   nubede palabras y las top-20 para un  análisis externo.\n",
    "  #####  Dependencias\n",
    "\n",
    "Los siguientes módulos son necesarios para ejecutar el código:\n",
    "\n",
    "- joblib==0.14.0\n",
    "- nltk==3.4.5\n",
    "- numpy==1.17.4\n",
    "- pandas==0.25.3\n",
    "- python-dateutil==2.8.1\n",
    "- pytz==2019.3\n",
    "- scikit-learn==0.21.3\n",
    "- scipy==1.3.3\n",
    "- six==1.13.0\n",
    "- sklearn==0.0\n",
    "\n",
    "## 1.4 Resultados\n",
    "\n",
    "Se extrajo el contenido semántico de los conjuntos de palabras y se realizó la nube de palabras en https://www.wordclouds.com.\n",
    "\n",
    "Responsable: Daniel Bustillos (juan.bustillos@itdp.org)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Configuraciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jupyter-daniel-\n",
      "[nltk_data]     bc/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#general\n",
    "\n",
    "import pandas as pd\n",
    "import sys\n",
    "from joblib import dump, load\n",
    "sys.path.append(\"./scripts\") \n",
    "\n",
    "# limpieza y Steamming\n",
    "from cleaning_steamming import CleanTools\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "\n",
    "# Análisis de importancia por TF-IDF\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Configuraciones\n",
    "\n",
    "Ninguna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Definición de parámetros\n",
    "definimos la columna a procesar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "columna = \"pregunta 3\"\n",
    "columns_not_duplicate = [\"id\"]\n",
    "columns_to_clean = columna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Importación de datos\n",
    "\n",
    "En esta sección cargue todos los datos que serán empleados en los análisis subsecuentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregunta 1</th>\n",
       "      <th>pregunta 2</th>\n",
       "      <th>pregunta 3</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Con niveles de servicio por trayecto</td>\n",
       "      <td>Agregar datos de flujo de movilidad de celular...</td>\n",
       "      <td>Dividir empleos -población económicamente acti...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sí, estrategias de marketing para nuevas perso...</td>\n",
       "      <td>zonas rojas</td>\n",
       "      <td>rutas de transporte con accesibilidad universal</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sí, para el análisis de tiempos de traslados y...</td>\n",
       "      <td>Incorporar líneas de transporte</td>\n",
       "      <td>Presencia de luminarias y de frentes activos</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          pregunta 1  \\\n",
       "0               Con niveles de servicio por trayecto   \n",
       "1  Sí, estrategias de marketing para nuevas perso...   \n",
       "2  Sí, para el análisis de tiempos de traslados y...   \n",
       "\n",
       "                                          pregunta 2  \\\n",
       "0  Agregar datos de flujo de movilidad de celular...   \n",
       "1                                        zonas rojas   \n",
       "2                    Incorporar líneas de transporte   \n",
       "\n",
       "                                          pregunta 3  id  \n",
       "0  Dividir empleos -población económicamente acti...   0  \n",
       "1    rutas de transporte con accesibilidad universal   1  \n",
       "2       Presencia de luminarias y de frentes activos   2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_encuesta = pd.read_csv(\"./data/respuestas-softlaubnch.csv\")\n",
    "df_encuesta[\"id\"] = df_encuesta.index.tolist()\n",
    "df_encuesta.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Procesamiento/Análisis/Modelos\n",
    "\n",
    "### 5.1 Limpieza:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separamos palabras en \"/\", util en campos normalizados \"Porqué_norm\" y \"Limitación_norm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encuesta[columna] = df_encuesta[columna].str.replace('/',' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicamos el archivo de limipieza y steamming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...text_cleaner\n",
      "...stop words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-daniel-bc/nlp-toolkit-espanol/./scripts/cleaning_steamming.py:34: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  s = s.str.normalize('NFKD').str.encode(\n"
     ]
    }
   ],
   "source": [
    "ct = CleanTools()\n",
    "df_proc = ct.text_cleaner(df_encuesta, columns_to_clean=columns_to_clean, columns_not_na=\"id\")\n",
    "field_clean = ct.stem_sentence_apply(limpiar=True,\n",
    "                       columns_not_duplicate=columns_not_duplicate,\n",
    "                       columns_to_clean=columns_to_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtramos respuestas vacías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_clean = [text for text in field_clean if text != \"\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exportamos para nube de palabras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dividir empleos poblacion economicamente activa genero rutas transporte accesibilidad universal presencia luminarias frentes activos pueda visualizar niveles pobreza incidencia delictiva raiz poblacion cantidades establecer equipamiento hace falta diversas necesidades zonas atracciones poner capas guarderias supermercados lugares trabajo remunerado informacion infraestructura urbana informacion inv inegi indices inseguridad informacion detallada transporte datos accesibilidad personas movilidad reducida informacion espacios publicos inseguros manzana horario viajes informacion poblacional sector indicar rampas pavimento tactil facilidades accesibilidad universal botones panico auxiliar mujeres victimas via publica camaras seguridad rampas identificar utas transporte 100 accesibilidad mapear zona mujeres cargo cuidado poderlas incluir capa cercania botones panico emergencia tomar cuenta dimensiones enhorno publico acuerdo movilidad nersonas discapacidad analisis ingresos poblacion trabajos informales violencia ocupacion mujeres incidencia delictiva indice rezago social conexion c5 capa viajes ninos personas mayores mujeres movilidad inclusiva tipos discapacidad grupo mujeres'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(field_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto_nube = \" \".join(field_clean)\n",
    "file2write=open(\"./data/procesado/palabras\" + columna + \".txt\",'w')\n",
    "file2write.write(texto_nube)\n",
    "file2write.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Vectorización TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicamos el vectorizador para conocer las top k palabras más importantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "corpus_vector = vectorizer.fit_transform(field_clean)\n",
    "feature_array = np.array(vectorizer.get_feature_names())\n",
    "mean_words = corpus_vector.toarray().mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacemos un nuevo dataframe y con la información de las palabras y su peso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_words_weighted = pd.DataFrame(columns=[\"word\", \"weight_Avg\"], index=[i for i in range(len(mean_words))])\n",
    "df_words_weighted[\"word\"] = feature_array\n",
    "df_words_weighted[\"weight_Avg\"] = mean_words\n",
    "df_words_weighted = df_words_weighted.sort_values(\"weight_Avg\", ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>weight_Avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mujeres</td>\n",
       "      <td>0.063662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>informacion</td>\n",
       "      <td>0.060717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>incidencia</td>\n",
       "      <td>0.052378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>delictiva</td>\n",
       "      <td>0.052378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>accesibilidad</td>\n",
       "      <td>0.047948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rampas</td>\n",
       "      <td>0.045769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>movilidad</td>\n",
       "      <td>0.045643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>transporte</td>\n",
       "      <td>0.043922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>viajes</td>\n",
       "      <td>0.039536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>poblacion</td>\n",
       "      <td>0.035407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ocupacion</td>\n",
       "      <td>0.030369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>discapacidad</td>\n",
       "      <td>0.029505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>inclusiva</td>\n",
       "      <td>0.028787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>personas</td>\n",
       "      <td>0.028130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>universal</td>\n",
       "      <td>0.027718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>horario</td>\n",
       "      <td>0.027686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>capa</td>\n",
       "      <td>0.027134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>zonas</td>\n",
       "      <td>0.026189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>c5</td>\n",
       "      <td>0.026189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>conexion</td>\n",
       "      <td>0.026189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>atracciones</td>\n",
       "      <td>0.026189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>panico</td>\n",
       "      <td>0.026128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>botones</td>\n",
       "      <td>0.026128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>sector</td>\n",
       "      <td>0.023149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>poblacional</td>\n",
       "      <td>0.023149</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             word  weight_Avg\n",
       "0         mujeres    0.063662\n",
       "1     informacion    0.060717\n",
       "2      incidencia    0.052378\n",
       "3       delictiva    0.052378\n",
       "4   accesibilidad    0.047948\n",
       "5          rampas    0.045769\n",
       "6       movilidad    0.045643\n",
       "7      transporte    0.043922\n",
       "8          viajes    0.039536\n",
       "9       poblacion    0.035407\n",
       "10      ocupacion    0.030369\n",
       "11   discapacidad    0.029505\n",
       "12      inclusiva    0.028787\n",
       "13       personas    0.028130\n",
       "14      universal    0.027718\n",
       "15        horario    0.027686\n",
       "16           capa    0.027134\n",
       "17          zonas    0.026189\n",
       "18             c5    0.026189\n",
       "19       conexion    0.026189\n",
       "20    atracciones    0.026189\n",
       "21         panico    0.026128\n",
       "22        botones    0.026128\n",
       "23         sector    0.023149\n",
       "24    poblacional    0.023149"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_words_weighted.head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_words_weighted = df_words_weighted.head(25)\n",
    "df_words_weighted.to_csv(\"./data/procesado/topk_palabras_\" + columna + \".csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Nube de palabras\n",
    "La nube de palabras se realizó en"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 Referencias\n",
    "\n",
    "[1] [https://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html](https://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html), visitado el 12/12/2019.\n",
    "\n",
    "\n",
    "[2] [http://www.tfidf.com](http://www.tfidf.com), visitado el 12/12/2019.\n",
    "\n",
    "[3] [https://scikit-learn.org/stable/modules/feature_extraction.html?highlight=tfid](https://scikit-learn.org/stable/modules/feature_extraction.html?highlight=tfidf), visitado el 12/12/2019.\n",
    "\n",
    "[4] [https://mlexplained.com/2017/12/28/a-practical-introduction-to-nmf-nonnegative-matrix-factorization/](https://mlexplained.com/2017/12/28/a-practical-introduction-to-nmf-nonnegative-matrix-factorization/) , visitado el 11/12/2019.\n",
    "\n",
    "[5] Blair, S.J., Bi, Y. & Mulvenna, M.D. Appl Intell (2019). https://doi.org/10.1007/s10489-019-01438-z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "main"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
